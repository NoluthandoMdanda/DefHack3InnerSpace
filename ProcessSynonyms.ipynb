{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Synonyms\n",
    "\n",
    "This notebook uses a combination of Python data science libraries and the Google Natural Language API (machine learning) to expand the vocabulary of the chatbot by generating synonyms for topics created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling google-cloud-datastore-1.15.3:\n",
      "  Successfully uninstalled google-cloud-datastore-1.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y google-cloud-datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-datastore\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/6c/bedcab39e8dc969f7a48d058dbacd69fc07ce3f817a03de875902016f667/google_cloud_datastore-1.15.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-datastore) (1.7.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-datastore) (1.22.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<2.0dev,>=1.4.0->google-cloud-datastore) (1.16.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.24.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<2.0dev,>=1.4.0->google-cloud-datastore) (1.32.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.6.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (3.13.0)\n",
      "Requirement already satisfied: futures>=3.2.0; python_version < \"3.2\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (3.2.0)\n",
      "Requirement already satisfied: pytz in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2018.4)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (44.0.0.post20200106)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2.18.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.31.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=1.24.0->google-cloud-core<2.0dev,>=1.4.0->google-cloud-datastore) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=1.24.0->google-cloud-core<2.0dev,>=1.4.0->google-cloud-datastore) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.6; python_version < \"3.6\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=1.24.0->google-cloud-core<2.0dev,>=1.4.0->google-cloud-datastore) (4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (2019.11.28)\n",
      "Requirement already satisfied: enum34>=1.0.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio<2.0dev,>=1.29.0; extra == \"grpc\"->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-datastore) (1.1.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.24.0->google-cloud-core<2.0dev,>=1.4.0->google-cloud-datastore) (0.4.8)\n",
      "Installing collected packages: google-cloud-datastore\n",
      "Successfully installed google-cloud-datastore-1.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading https://files.pythonhosted.org/packages/2a/14/49a8afaaa66fb49cda8e60512f0fc07594232fb10ea6aa8995c069172cf6/inflect-3.0.2-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata (from inflect)\n",
      "  Downloading https://files.pythonhosted.org/packages/98/b8/8ec57a8ef46fbe7f185318c7ff7df9a06c9df451d9a59a067bfa851bb828/importlib_metadata-2.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: configparser>=3.5; python_version < \"3\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from importlib-metadata->inflect) (3.5.3)\n",
      "Collecting zipp>=0.5 (from importlib-metadata->inflect)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/0a/67556e9b7782df7118c1f49bdc494da5e5e429c93aa77965f33e81287c8c/zipp-1.2.0-py2.py3-none-any.whl\n",
      "Collecting contextlib2; python_version < \"3\" (from importlib-metadata->inflect)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/60/370352f7ef6aa96c52fb001831622f50f923c1d575427d021b8ab3311236/contextlib2-0.6.0.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pathlib2; python_version < \"3\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from importlib-metadata->inflect) (2.3.5)\n",
      "Requirement already satisfied: six in /usr/local/envs/py2env/lib/python2.7/site-packages (from pathlib2; python_version < \"3\"->importlib-metadata->inflect) (1.16.0)\n",
      "Requirement already satisfied: scandir; python_version < \"3.5\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from pathlib2; python_version < \"3\"->importlib-metadata->inflect) (1.10.0)\n",
      "Installing collected packages: contextlib2, zipp, importlib-metadata, inflect\n",
      "Successfully installed contextlib2-0.6.0.post1 importlib-metadata-2.1.1 inflect-3.0.2 zipp-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install inflect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit Reset Session > Restart, then resume with the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only need to do this once...\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_client = datastore.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = datastore.Client()\n",
    "query = client.query(kind='Topic')\n",
    "results = list(query.fetch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "plurals = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Synonyms with Python\n",
    "Split the topic into words and use PyDictionary to look up synonyms in a \"thesaurus\" for each word.  Store these in Datastore and link them back to the topic.  Note this section uses the concept of \"stop words\" to filter out articles and other parts of speech that don't contribute to meaning of the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/ipykernel/__main__.py:2: DeprecationWarning: the sets module is deprecated\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/unidecode/__init__.py:46: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n",
      "  _warn_if_not_unicode(string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anxiety disorder anxiety Set([u'anxieties', u'anxiousnesses', u'anxiety', u'anxiousness'])\n",
      "anxiety disorder disorder Set([u'disorders', u'disorderlinesses', u'upset', u'upsets', u'disorderliness', u'disorder'])\n",
      "anxious anxious Set([])\n",
      "appetite loss appetite Set([u'appetences', u'appetites', u'appetency', u'appetence', u'appetencies', u'appetite'])\n",
      "appetite loss loss Set([u'reds', u'loss', u'releases', u'expirations', u'exits', u'deprivation', u'losses', u'passings', u'departure', u'going', u'exit', u'departures', u'goings', u'release', u'passing', u'deprivations', u'red', u'expiration'])\n",
      "avoid stress avoid Set([])\n",
      "avoid stress stress Set([u'stresses', u'tension', u'stress', u'focuses', u'strains', u'tensions', u'accents', u'tensenesses', u'accent', u'focus', u'strain', u'emphasis', u'tenseness', u'emphases'])\n",
      "cognitive behavioural therapy cognitive Set([])\n",
      "cognitive behavioural therapy behavioural Set([])\n",
      "cognitive behavioural therapy therapy Set([u'therapy', u'therapies'])\n",
      "cold hands cold Set([])\n",
      "cold hands hands Set([u'deal', u'scripts', u'manus', u'paws', u'mitts', u'custody', u'paw', u'mens', u'workforces', u'custodies', u'manuses', u'mitt', u'men', u'workforce', u'hand', u'hands', u'manpower', u'script', u'handwritings', u'deals', u'manpowers', u'handwriting'])\n",
      "creative work creative Set([])\n",
      "creative work work Set([u'oeuvre', u'oeuvres', u'employment', u'study', u'work', u'workplaces', u'workplace', u'employments', u'works', u'studies'])\n",
      "depression depression Set([u'impression', u'Depressions', u'slump', u'slumps', u'imprint', u'depression', u'lows', u'impressions', u'depressions', u'imprints', u'Depression', u'low'])\n",
      "exercise exercise Set([u'usages', u'utilisation', u'examples', u'employment', u'use', u'utilization', u'exercising', u'usage', u'employments', u'exercise', u'workout', u'practice', u'exercisings', u'recitation', u'uses', u'exercises', u'workouts', u'drills', u'utilisations', u'recitations', u'practices', u'drill', u'utilizations', u'example'])\n",
      "fear fear Set([u'venerations', u'veneration', u'reverences', u'fright', u'cares', u'fearfulnesses', u'fears', u'awe', u'concerns', u'frights', u'reverence', u'fear', u'care', u'awes', u'fearfulness', u'concern'])\n",
      "generalized anxiety disorder. generalized Set([])\n",
      "generalized anxiety disorder. anxiety Set([u'anxieties', u'anxiousnesses', u'anxiety', u'anxiousness'])\n",
      "generalized anxiety disorder. disorder. Set([])\n",
      "healthcare healthcare Set([u'healthcares', u'healthcare'])\n",
      "healthy diet healthy Set([])\n",
      "healthy diet diet Set([u'diets', u'dieting', u'diet', u'dietings'])\n",
      "loss of intent loss Set([u'reds', u'loss', u'releases', u'expirations', u'exits', u'deprivation', u'losses', u'passings', u'departure', u'going', u'exit', u'departures', u'goings', u'release', u'passing', u'deprivations', u'red', u'expiration'])\n",
      "loss of intent intent Set([u'intents', u'spirits', u'intentions', u'designs', u'purposes', u'aims', u'aim', u'intention', u'intent', u'purpose', u'purport', u'design', u'purports', u'spirit'])\n",
      "loss of pleasure loss Set([u'reds', u'loss', u'releases', u'expirations', u'exits', u'deprivation', u'losses', u'passings', u'departure', u'going', u'exit', u'departures', u'goings', u'release', u'passing', u'deprivations', u'red', u'expiration'])\n",
      "loss of pleasure pleasure Set([u'pleasances', u'pleasures', u'pleasance', u'joy', u'delight', u'joys', u'pleasure', u'delights'])\n",
      "no concentration concentration Set([u'engrossments', u'compactnesses', u'tightness', u'denseness', u'assiduity', u'density', u'immersion', u'absorption', u'assiduousnesses', u'assiduities', u'absorptions', u'engrossment', u'compactness', u'concentrations', u'concentration', u'densenesses', u'assiduousness', u'immersions', u'tightnesses', u'densities'])\n",
      "obsessive compulsive disorder obsessive Set([u'obsessive', u'obsessives'])\n",
      "obsessive compulsive disorder compulsive Set([u'compulsive', u'compulsives'])\n",
      "obsessive compulsive disorder disorder Set([u'disorders', u'disorderlinesses', u'upset', u'upsets', u'disorderliness', u'disorder'])\n",
      "overeating overeating Set([u'overeatings', u'gula', u'gluttony', u'overeating', u'gluttonies', u'gulas'])\n",
      "panic panic Set([u'affright', u'terrors', u'scares', u'affrights', u'terror', u'panic', u'scare', u'panics'])\n",
      "panic disorder panic Set([u'affright', u'terrors', u'scares', u'affrights', u'terror', u'panic', u'scare', u'panics'])\n",
      "panic disorder disorder Set([u'disorders', u'disorderlinesses', u'upset', u'upsets', u'disorderliness', u'disorder'])\n",
      "psychotherapy-talk therapy psychotherapy-talk Set([])\n",
      "psychotherapy-talk therapy therapy Set([u'therapy', u'therapies'])\n",
      "pyschological counselling pyschological Set([])\n",
      "pyschological counselling counselling Set([u'counselings', u'counsel', u'counselling', u'guidance', u'direction', u'directions', u'counsels', u'counsellings', u'counseling', u'guidances'])\n",
      "relaxation therapy relaxation Set([u'liberalizations', u'liberalisation', u'rests', u'ease', u'relaxation', u'reposes', u'loosening', u'rest', u'relaxations', u'slackenings', u'easinesses', u'loosenings', u'easiness', u'repose', u'liberalization', u'eases', u'slackening', u'liberalisations'])\n",
      "relaxation therapy therapy Set([u'therapy', u'therapies'])\n",
      "social anxiety disorder social Set([])\n",
      "social anxiety disorder anxiety Set([u'anxieties', u'anxiousnesses', u'anxiety', u'anxiousness'])\n",
      "social anxiety disorder disorder Set([u'disorders', u'disorderlinesses', u'upset', u'upsets', u'disorderliness', u'disorder'])\n",
      "sport sport Set([u'variation', u'play', u'mutant', u'plays', u'funs', u'sportswomen', u'athletic', u'sportswoman', u'variations', u'mutants', u'sportsman', u'summercater', u'sports', u'sportsmen', u'summercaters', u'mutations', u'mutation', u'fun', u'athletics', u'sport'])\n",
      "sweaty sweaty Set([])\n",
      "symptoms symptoms Set([u'symptoms', u'symptom'])\n",
      "thoughts of death thoughts Set([u'cerebration', u'persuasions', u'intellections', u'sentiment', u'cerebrations', u'thinking', u'views', u'mentation', u'idea', u'ideas', u'thought', u'mentations', u'intellection', u'opinions', u'view', u'opinion', u'thinkings', u'persuasion', u'thoughts', u'sentiments'])\n",
      "thoughts of death death Set([u'decease', u'ends', u'death', u'last', u'dying', u'deaths', u'deceases', u'Deaths', u'demises', u'expiry', u'destructions', u'expiries', u'Death', u'demise', u'lasts', u'end', u'dyings', u'destruction'])\n",
      "tiredness tiredness Set([u'fatigues', u'wearinesses', u'weariness', u'tirednesses', u'fatigue', u'tiredness'])\n",
      "treatment treatment Set([u'handling', u'interventions', u'discourses', u'discussion', u'treatments', u'discourse', u'treatment', u'discussions', u'handlings', u'intervention'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from sets import Set\n",
    "\n",
    "for result in results:\n",
    "  for word in result.key.name.split():\n",
    "    \n",
    "    if word in stop:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    synonyms = Set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "      \n",
    "      if \".n.\" in str(syn):\n",
    "\n",
    "        for l in syn.lemmas():\n",
    "          lemma = l.name()\n",
    "          if (lemma.isalpha()):\n",
    "            synonyms.add(lemma)\n",
    "            synonyms.add(plurals.plural(lemma))\n",
    "      \n",
    "      if \".a.\" in str(syn):\n",
    "        synonyms = Set()\n",
    "        break\n",
    "\n",
    "    print result.key.name, word, synonyms\n",
    "    \n",
    "    kind = 'Synonym'\n",
    "    synonym_key = datastore_client.key(kind, result.key.name)\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    \n",
    "    synonym_key = datastore_client.key(kind, word)\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    \n",
    "    for dictionary_synonym in synonyms:\n",
    "      \n",
    "      synonym_key = datastore_client.key(kind, dictionary_synonym)\n",
    "\n",
    "      synonym = datastore.Entity(key=synonym_key)\n",
    "      synonym['synonym'] = result.key.name\n",
    "\n",
    "      datastore_client.put(synonym)\n",
    "      \n",
    "    synonym_key = datastore_client.key(kind, plurals.plural(word))\n",
    "\n",
    "    synonym = datastore.Entity(key=synonym_key)\n",
    "    synonym['synonym'] = result.key.name\n",
    "\n",
    "    datastore_client.put(synonym)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
